# ğŸ‡§ğŸ‡· 
# ğŸ½ï¸ AnÃ¡lise do Funil e Teste A/A/B de um App AlimentÃ­cio

Trabalhar neste projeto foi quase como observar a vida do app pelos olhos dos prÃ³prios usuÃ¡rios. A ideia era entender como as pessoas navegavam dentro do aplicativo â€” desde o primeiro clique atÃ© a etapa final de compra â€” e descobrir onde, ao longo do caminho, elas acabavam ficando pelo meio do caminho.

Comecei analisando o funil de eventos, identificando quantos usuÃ¡rios avanÃ§avam de uma etapa para outra e em quais pontos a maior parte deles se perdia. Essa parte trouxe uma visÃ£o clara sobre gargalos e comportamentos inesperados dentro do fluxo.

Depois veio a segunda metade do projeto: estudar um teste A/A/B. Os designers queriam trocar a fonte do app inteiro, e havia a preocupaÃ§Ã£o de que a mudanÃ§a assustasse os usuÃ¡rios. Para tirar essa dÃºvida, trÃªs grupos foram criados: dois grupos A (controle) e um grupo B (teste, com as fontes novas). A ideia era nÃ£o sÃ³ comparar o desempenho das fontes, mas tambÃ©m verificar se os dois grupos de controle eram consistentes entre si â€” algo essencial num teste bem conduzido.

Analisei a distribuiÃ§Ã£o de eventos, comparei proporÃ§Ãµes entre os grupos, verifiquei diferenÃ§as estatÃ­sticas e avaliei a significÃ¢ncia das mudanÃ§as observadas. O processo envolveu desde verificaÃ§Ã£o da qualidade dos dados atÃ© o teste de hipÃ³teses, sempre cuidando para que o volume de testes nÃ£o comprometesse a interpretaÃ§Ã£o final.

No fim, o projeto trouxe uma leitura completa: como os usuÃ¡rios realmente usam o app, como avanÃ§am no funil, e se a mudanÃ§a visual planejada era segura ou nÃ£o para ser levada adiante.

# ğŸ‡ºğŸ‡¸ 
# ğŸ½ï¸ User Behavior Analysis and A/A/B Testing for a Food App

This project felt like stepping directly into the userâ€™s journey inside the app. The goal was to understand how people move through the product â€” from their very first interaction all the way to the purchase stage â€” and to see where they tend to drop off.

I started by breaking down the entire event funnel. That meant identifying how many users reached each stage, how many didnâ€™t, and which steps caused the biggest losses. This alone already revealed a lot about the product flow and where improvements could make the biggest difference.

The second phase was all about an A/A/B experiment. The design team wanted to change the appâ€™s font across the entire interface, but there was concern that the new look might push users away. To validate (or invalidate) that fear, we set up three groups: two control groups with the original font and one test group with the new typography.

I compared event behavior across the groups, checked whether the control groups were statistically similar (a key requirement), calculated conversions, analyzed event distributions, and ran hypothesis tests to see if any differences were real or just noise. I also considered the number of tests being performed to avoid drawing conclusions from false positives.

By the end, the analysis offered a full picture: how users interact with the app, how smoothly they move through the funnel, and whether the updated font was safe to roll out without jeopardizing user behavior.
